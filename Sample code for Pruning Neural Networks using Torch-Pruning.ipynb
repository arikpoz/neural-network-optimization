{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "VBLrmqyAcGSG",
   "metadata": {
    "id": "VBLrmqyAcGSG"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac09b083-ed2a-470c-bbeb-8248ae6e0949",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3119,
     "status": "ok",
     "timestamp": 1744237896821,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "ac09b083-ed2a-470c-bbeb-8248ae6e0949",
    "outputId": "40401e10-db42-4b13-9003-1ea30503b4b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-pruning in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-pruning) (2.6.0+cu124)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-pruning) (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch-pruning) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-pruning) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5ee7cd-b308-4d70-92a4-982fba032483",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8670,
     "status": "ok",
     "timestamp": 1744237905510,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "ec5ee7cd-b308-4d70-92a4-982fba032483",
    "outputId": "b001fe09-3326-4c2f-f20f-74c88b6276dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch_pruning as tp\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nFmIVfsraiGD",
   "metadata": {
    "id": "nFmIVfsraiGD"
   },
   "source": [
    "## Get CIFAR-10 train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3924dc20-17e6-46f0-9be9-5b75b6a369d4",
   "metadata": {
    "executionInfo": {
     "elapsed": 2482,
     "status": "ok",
     "timestamp": 1744237907990,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "3924dc20-17e6-46f0-9be9-5b75b6a369d4"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform),\n",
    "    batch_size=128, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform),\n",
    "    batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZvoSXGQZaOSo",
   "metadata": {
    "id": "ZvoSXGQZaOSo"
   },
   "source": [
    "## Adjust ResNet18 network for CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0517cc6-5a61-42e1-9ae3-8a11fdf62c54",
   "metadata": {
    "executionInfo": {
     "elapsed": 669,
     "status": "ok",
     "timestamp": 1744237908661,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "f0517cc6-5a61-42e1-9ae3-8a11fdf62c54"
   },
   "outputs": [],
   "source": [
    "def get_resnet18_for_cifar10():\n",
    "    model = models.resnet18(weights=None, num_classes=10)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    return model.to(device)\n",
    "\n",
    "full_model = get_resnet18_for_cifar10()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vPWaCf2AccVc",
   "metadata": {
    "id": "vPWaCf2AccVc"
   },
   "source": [
    "## Define Train and Evaluate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "752335ff-ff2e-44e3-80d4-a2bc19ea16e2",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1744237908675,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "752335ff-ff2e-44e3-80d4-a2bc19ea16e2"
   },
   "outputs": [],
   "source": [
    "def train(model, loader, epochs, lr=0.01, save_path=\"model.pth\", silent=False):\n",
    "    if os.path.exists(save_path):\n",
    "        if not silent:\n",
    "            print(f\"Model already trained. Loading from {save_path}\")\n",
    "        model.load_state_dict(torch.load(save_path))\n",
    "        return\n",
    "\n",
    "    # no saved model found. training from given model state\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if not silent:\n",
    "            print(f\"Epoch {epoch+1}: loss={loss.item():.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    if not silent:\n",
    "        print(f\"Training complete. Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "LYyweOP8bNUP",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1744237908692,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "LYyweOP8bNUP"
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x).argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G9udKjwnc5f2",
   "metadata": {
    "id": "G9udKjwnc5f2"
   },
   "source": [
    "## Define helper functions to measure latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be34caa9-5009-41e7-9cfc-4d4131801e0e",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1744237908707,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "be34caa9-5009-41e7-9cfc-4d4131801e0e"
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.starter = torch.cuda.Event(enable_timing=True)\n",
    "            self.ender = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    def start(self):\n",
    "        if self.use_cuda:\n",
    "            self.starter.record()\n",
    "        else:\n",
    "            self.start_time = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        if self.use_cuda:\n",
    "            self.ender.record()\n",
    "            torch.cuda.synchronize()\n",
    "            return self.starter.elapsed_time(self.ender)  # ms\n",
    "        else:\n",
    "            return (time.time() - self.start_time) * 1000  # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "376b34a4-4bb7-49ee-9aef-8a45d538a11f",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1744237908727,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "376b34a4-4bb7-49ee-9aef-8a45d538a11f"
   },
   "outputs": [],
   "source": [
    "def estimate_latency(model, example_inputs, repetitions=50):\n",
    "    timer = Timer()\n",
    "    timings = np.zeros((repetitions, 1))\n",
    "\n",
    "    # warm-up\n",
    "    for _ in range(5):\n",
    "        _ = model(example_inputs)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for rep in range(repetitions):\n",
    "            timer.start()\n",
    "            _ = model(example_inputs)\n",
    "            elapsed = timer.stop()\n",
    "            timings[rep] = elapsed\n",
    "\n",
    "    return np.mean(timings), np.std(timings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bK9iZKcUmi",
   "metadata": {
    "id": "70bK9iZKcUmi"
   },
   "source": [
    "## Train and Evaluate full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aef0a3-9114-454f-9c60-34669c3f4d07",
   "metadata": {
    "id": "42aef0a3-9114-454f-9c60-34669c3f4d07"
   },
   "outputs": [],
   "source": [
    "train(full_model, train_loader, epochs=10, save_path=\"full_model.pth\")\n",
    "accuracy_full = evaluate(full_model)\n",
    "\n",
    "example_input = torch.rand(128, 3, 32, 32).to(device)\n",
    "macs, parameters = tp.utils.count_ops_and_params(full_model, example_input)\n",
    "latency_mu, latency_std = estimate_latency(full_model, example_input)\n",
    "print(f\"[full model] \\t\\tMACs: {macs/1e9:.2f} G, \\tParameters: {parameters/1e6:.2f} M, \\tLatency: {latency_mu:.2f} ± {latency_std:.2f} ms \\tAccuracy: {accuracy_full*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yjU8vzQ_dYaK",
   "metadata": {
    "id": "yjU8vzQ_dYaK"
   },
   "source": [
    "## Prune by L2 magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a7c5b0-6f07-4ab3-9bd8-5ac5d72b8392",
   "metadata": {
    "id": "32a7c5b0-6f07-4ab3-9bd8-5ac5d72b8392"
   },
   "outputs": [],
   "source": [
    "# clone full model before pruning\n",
    "pruned_model = copy.deepcopy(full_model)\n",
    "pruned_model = pruned_model.to(device)\n",
    "\n",
    "# set which layers to skip pruning. important to keep final classifier layer\n",
    "ignored_layers = []\n",
    "for m in pruned_model.modules():\n",
    "    if isinstance(m, torch.nn.Linear) and m.out_features == 10:\n",
    "        ignored_layers.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8628cf3-6e5d-4e79-9da0-63c1b7eab6ab",
   "metadata": {
    "id": "c8628cf3-6e5d-4e79-9da0-63c1b7eab6ab"
   },
   "outputs": [],
   "source": [
    "# iterative pruning\n",
    "iterative_steps = 20\n",
    "pruner = tp.pruner.MagnitudePruner(\n",
    "    model = pruned_model,\n",
    "    example_inputs = example_input,\n",
    "    importance = tp.importance.MagnitudeImportance(p=2),\n",
    "    pruning_ratio = 1,\n",
    "    iterative_steps = iterative_steps,\n",
    "    ignored_layers = ignored_layers,\n",
    "    round_to = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc8ae77-7910-4f42-8c3a-c35b38ade0b8",
   "metadata": {
    "id": "edc8ae77-7910-4f42-8c3a-c35b38ade0b8"
   },
   "outputs": [],
   "source": [
    "for iter in range(iterative_steps):\n",
    "    # prune\n",
    "    pruner.step()\n",
    "    # evaluate after prune\n",
    "    acc_before = evaluate(pruned_model)\n",
    "    # fine-tune pruned model\n",
    "    train(pruned_model, train_loader, epochs=1, save_path=f\"pruned_model_{iter}.pth\", silent=True)\n",
    "    # evaluate after fine-tune\n",
    "    acc_after = evaluate(pruned_model)\n",
    "    # count MACs and parameters\n",
    "    macs, parameters = tp.utils.count_ops_and_params(pruned_model, example_input)\n",
    "    latency_mu, latency_std = estimate_latency(pruned_model, example_input)\n",
    "    current_pruning_ratio = 1 / iterative_steps * (iter + 1)\n",
    "    print(f\"[pruned model] \\tPruning ratio: {current_pruning_ratio:.2f}, \\tMACs: {macs/1e9:.2f} G, \\tParameters: {parameters/1e6:.2f} M, \\tLatency: {latency_mu:.2f} ± {latency_std:.2f} ms \\tAccuracy pruned: {acc_before*100:.2f}%\\tFinetuned: {acc_after*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8n3xnrGJrI6O",
   "metadata": {
    "id": "8n3xnrGJrI6O"
   },
   "source": [
    "## Extra fine-tune last pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60JXuq3ZWJQh",
   "metadata": {
    "id": "60JXuq3ZWJQh"
   },
   "outputs": [],
   "source": [
    "train(pruned_model, train_loader, epochs=5, save_path=f\"pruned_model_final_tuning.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HO3Sz_XQW0Eq",
   "metadata": {
    "id": "HO3Sz_XQW0Eq"
   },
   "outputs": [],
   "source": [
    "accuracy_final = evaluate(pruned_model)\n",
    "print(f\"Pruned extra fine-tuned model accuracy: {accuracy_final*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
