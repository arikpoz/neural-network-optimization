{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "VBLrmqyAcGSG",
   "metadata": {
    "id": "VBLrmqyAcGSG"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7f6ca7-3398-432d-a696-de4227780b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
      "Requirement already satisfied: nvidia-modelopt[all] in /usr/local/lib/python3.10/dist-packages (0.27.0)\n",
      "Requirement already satisfied: nvidia-modelopt-core==0.27.0 in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (0.27.0)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (1.11.1.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (1.24.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (23.2)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (2.11.3)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (14.0.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (1.15.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (4.67.1)\n",
      "Requirement already satisfied: cppimport in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (22.8.2)\n",
      "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (13.4.1)\n",
      "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (1.16.1)\n",
      "Requirement already satisfied: onnxconverter-common in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (1.14.0)\n",
      "Requirement already satisfied: onnx-graphsurgeon in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (0.5.7)\n",
      "Requirement already satisfied: onnxruntime-gpu~=1.20.1 in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (1.20.2)\n",
      "Requirement already satisfied: onnxsim in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (0.4.36)\n",
      "Requirement already satisfied: pulp in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (3.1.1)\n",
      "Requirement already satisfied: pynvml>=11.5.0 in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (12.0.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (2024.11.6)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (0.5.3)\n",
      "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (2.6.0)\n",
      "Requirement already satisfied: torchprofile>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (0.0.4)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (0.21.0)\n",
      "Requirement already satisfied: accelerate>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (1.6.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (3.5.0)\n",
      "Requirement already satisfied: diffusers>=0.32.2 in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (0.33.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (0.30.2)\n",
      "Requirement already satisfied: peft>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (0.15.1)\n",
      "Requirement already satisfied: transformers>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[all]) (4.51.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=1.0.0->nvidia-modelopt[all]) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=1.0.0->nvidia-modelopt[all]) (6.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->nvidia-modelopt[all]) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (3.11.16)\n",
      "Requirement already satisfied: importlib_metadata in /usr/lib/python3/dist-packages (from diffusers>=0.32.2->nvidia-modelopt[all]) (4.6.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.32.2->nvidia-modelopt[all]) (9.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.24.0->nvidia-modelopt[all]) (4.13.1)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu~=1.20.1->nvidia-modelopt[all]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu~=1.20.1->nvidia-modelopt[all]) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu~=1.20.1->nvidia-modelopt[all]) (3.20.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu~=1.20.1->nvidia-modelopt[all]) (1.13.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->nvidia-modelopt[all]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->nvidia-modelopt[all]) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->nvidia-modelopt[all]) (0.4.0)\n",
      "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pynvml>=11.5.0->nvidia-modelopt[all]) (12.570.86)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime-gpu~=1.20.1->nvidia-modelopt[all]) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.48.0->nvidia-modelopt[all]) (0.21.1)\n",
      "Requirement already satisfied: mako in /usr/local/lib/python3.10/dist-packages (from cppimport->nvidia-modelopt[all]) (1.3.9)\n",
      "Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (from cppimport->nvidia-modelopt[all]) (2.13.6)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x->nvidia-modelopt[all]) (0.8.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->nvidia-modelopt[all]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->nvidia-modelopt[all]) (2.16.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all]) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all]) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all]) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all]) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all]) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all]) (6.4.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all]) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all]) (1.19.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->nvidia-modelopt[all]) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=3.0.0->nvidia-modelopt[all]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=3.0.0->nvidia-modelopt[all]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=3.0.0->nvidia-modelopt[all]) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=3.0.0->nvidia-modelopt[all]) (2022.12.7)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime-gpu~=1.20.1->nvidia-modelopt[all]) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2->nvidia-modelopt[all]) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=3.0.0->nvidia-modelopt[all]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=3.0.0->nvidia-modelopt[all]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=3.0.0->nvidia-modelopt[all]) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->nvidia-modelopt[all]) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"nvidia-modelopt[all]\" -U --extra-index-url https://pypi.nvidia.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5ee7cd-b308-4d70-92a4-982fba032483",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8670,
     "status": "ok",
     "timestamp": 1744237905510,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "ec5ee7cd-b308-4d70-92a4-982fba032483",
    "outputId": "b001fe09-3326-4c2f-f20f-74c88b6276dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import modelopt.torch.prune as mtp\n",
    "import modelopt.torch.opt as mto\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nFmIVfsraiGD",
   "metadata": {
    "id": "nFmIVfsraiGD"
   },
   "source": [
    "## Get CIFAR-10 train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3924dc20-17e6-46f0-9be9-5b75b6a369d4",
   "metadata": {
    "executionInfo": {
     "elapsed": 2482,
     "status": "ok",
     "timestamp": 1744237907990,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "3924dc20-17e6-46f0-9be9-5b75b6a369d4"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform),\n",
    "    batch_size=128, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform),\n",
    "    batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZvoSXGQZaOSo",
   "metadata": {
    "id": "ZvoSXGQZaOSo"
   },
   "source": [
    "## Adjust ResNet18 network for CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0517cc6-5a61-42e1-9ae3-8a11fdf62c54",
   "metadata": {
    "executionInfo": {
     "elapsed": 669,
     "status": "ok",
     "timestamp": 1744237908661,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "f0517cc6-5a61-42e1-9ae3-8a11fdf62c54"
   },
   "outputs": [],
   "source": [
    "def get_resnet18_for_cifar10():\n",
    "    model = models.resnet18(weights=None, num_classes=10)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    return model.to(device)\n",
    "\n",
    "full_model = get_resnet18_for_cifar10()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vPWaCf2AccVc",
   "metadata": {
    "id": "vPWaCf2AccVc"
   },
   "source": [
    "## Define Train and Evaluate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "752335ff-ff2e-44e3-80d4-a2bc19ea16e2",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1744237908675,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "752335ff-ff2e-44e3-80d4-a2bc19ea16e2"
   },
   "outputs": [],
   "source": [
    "def train(model, loader, epochs, lr=0.01, save_path=\"model.pth\", silent=False):\n",
    "    if os.path.exists(save_path):\n",
    "        if not silent:\n",
    "            print(f\"Model already trained. Loading from {save_path}\")\n",
    "        model.load_state_dict(torch.load(save_path))\n",
    "        return\n",
    "\n",
    "    # no saved model found. training from given model state\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if not silent:\n",
    "            print(f\"Epoch {epoch+1}: loss={loss.item():.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    if not silent:\n",
    "        print(f\"Training complete. Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "LYyweOP8bNUP",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1744237908692,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "LYyweOP8bNUP"
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x).argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G9udKjwnc5f2",
   "metadata": {
    "id": "G9udKjwnc5f2"
   },
   "source": [
    "## Define helper functions to measure latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be34caa9-5009-41e7-9cfc-4d4131801e0e",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1744237908707,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "be34caa9-5009-41e7-9cfc-4d4131801e0e"
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.starter = torch.cuda.Event(enable_timing=True)\n",
    "            self.ender = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    def start(self):\n",
    "        if self.use_cuda:\n",
    "            self.starter.record()\n",
    "        else:\n",
    "            self.start_time = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        if self.use_cuda:\n",
    "            self.ender.record()\n",
    "            torch.cuda.synchronize()\n",
    "            return self.starter.elapsed_time(self.ender)  # ms\n",
    "        else:\n",
    "            return (time.time() - self.start_time) * 1000  # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "376b34a4-4bb7-49ee-9aef-8a45d538a11f",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1744237908727,
     "user": {
      "displayName": "Arik Poznanski",
      "userId": "17215250503704805691"
     },
     "user_tz": -180
    },
    "id": "376b34a4-4bb7-49ee-9aef-8a45d538a11f"
   },
   "outputs": [],
   "source": [
    "def estimate_latency(model, example_inputs, repetitions=50):\n",
    "    timer = Timer()\n",
    "    timings = np.zeros((repetitions, 1))\n",
    "\n",
    "    # warm-up\n",
    "    for _ in range(5):\n",
    "        _ = model(example_inputs)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for rep in range(repetitions):\n",
    "            timer.start()\n",
    "            _ = model(example_inputs)\n",
    "            elapsed = timer.stop()\n",
    "            timings[rep] = elapsed\n",
    "\n",
    "    return np.mean(timings), np.std(timings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bK9iZKcUmi",
   "metadata": {
    "id": "70bK9iZKcUmi"
   },
   "source": [
    "## Train and Evaluate full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42aef0a3-9114-454f-9c60-34669c3f4d07",
   "metadata": {
    "id": "42aef0a3-9114-454f-9c60-34669c3f4d07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already trained. Loading from full_model.pth\n",
      "[full model] \t\tLatency: 16.74 ± 0.06 ms \tAccuracy: 76.85%\n"
     ]
    }
   ],
   "source": [
    "train(full_model, train_loader, epochs=10, save_path=\"full_model.pth\")\n",
    "accuracy_full = evaluate(full_model)\n",
    "\n",
    "example_input = torch.rand(128, 3, 32, 32).to(device)\n",
    "latency_mu, latency_std = estimate_latency(full_model, example_input)\n",
    "print(f\"[full model] \\t\\tLatency: {latency_mu:.2f} ± {latency_std:.2f} ms \\tAccuracy: {accuracy_full*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yjU8vzQ_dYaK",
   "metadata": {
    "id": "yjU8vzQ_dYaK"
   },
   "source": [
    "## Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32a7c5b0-6f07-4ab3-9bd8-5ac5d72b8392",
   "metadata": {
    "id": "32a7c5b0-6f07-4ab3-9bd8-5ac5d72b8392"
   },
   "outputs": [],
   "source": [
    "# clone full model before pruning\n",
    "pruned_model = copy.deepcopy(full_model)\n",
    "pruned_model = pruned_model.to(device)\n",
    "\n",
    "# set which layers to skip pruning. important to keep final classifier layer\n",
    "ignored_layers = []\n",
    "for m in pruned_model.modules():\n",
    "    if isinstance(m, torch.nn.Linear) and m.out_features == 10:\n",
    "        ignored_layers.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8628cf3-6e5d-4e79-9da0-63c1b7eab6ab",
   "metadata": {
    "id": "c8628cf3-6e5d-4e79-9da0-63c1b7eab6ab"
   },
   "outputs": [],
   "source": [
    "\n",
    "   \n",
    "# iterative pruning\n",
    "iterative_steps = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edc8ae77-7910-4f42-8c3a-c35b38ade0b8",
   "metadata": {
    "id": "edc8ae77-7910-4f42-8c3a-c35b38ade0b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Profiling the following subnets from the given model: ('min', 'centroid', 'max').\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                                                             \u001b[0m\n",
      "\u001b[3m                              Profiling Results                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmin         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcentroid    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax/min ratio\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ flops        │ 7.46G        │ 21.52G       │ 71.09G       │ 9.54          │\n",
      "│ params       │ 586.60K      │ 4.60M        │ 11.16M       │ 19.03         │\n",
      "└──────────────┴──────────────┴──────────────┴──────────────┴───────────────┘\n",
      "\u001b[3m                                              \u001b[0m\n",
      "\u001b[3m            Constraints Evaluation            \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m              \u001b[0m┃\u001b[1m              \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSatisfiable \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
      "│ params       │ 10.05M       │ True         │\n",
      "└──────────────┴──────────────┴──────────────┘\n",
      "\n",
      "\n",
      "Search Space Summary:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "* conv1.out_channels                                                               [32, 64]\n",
      "  conv1.in_channels                                                                [3]\n",
      "  bn1.num_features                                                                 [32, 64]\n",
      "  layer1.depth                                                                     [2]\n",
      "* layer1.0.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn1.num_features                                                        [32, 64]\n",
      "  layer1.0.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn2.num_features                                                        [32, 64]\n",
      "* layer1.1.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn1.num_features                                                        [32, 64]\n",
      "  layer1.1.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn2.num_features                                                        [32, 64]\n",
      "  layer2.depth                                                                     [2]\n",
      "* layer2.0.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer2.0.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "* layer2.0.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.0.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.out_channels                                               [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.in_channels                                                [32, 64]\n",
      "  layer2.0.downsample.1.num_features                                               [32, 64, 96, 128]\n",
      "* layer2.1.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.1.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer3.depth                                                                     [2]\n",
      "* layer3.0.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer3.0.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.0.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.out_channels                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.in_channels                                                [32, 64, 96, 128]\n",
      "  layer3.0.downsample.1.num_features                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.1.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.depth                                                                     [2]\n",
      "* layer4.0.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.0.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv2.out_channels                                                      [512]\n",
      "  layer4.0.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.downsample.0.out_channels                                               [512]\n",
      "  layer4.0.downsample.0.in_channels                                                [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer4.1.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv1.in_channels                                                       [512]\n",
      "  layer4.1.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv2.out_channels                                                      [512]\n",
      "  layer4.1.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of configurable hparams: 11\n",
      "Total size of the search space: 6.71e+07\n",
      "Note: all constraints can be satisfied within the search space!\n",
      "\n",
      "\n",
      "Beginning pre-search estimation. If the runtime of score function is longer than a few minutes, consider subsampling the dataset used in score function. \n",
      "A PyTorch dataset can be subsampled using torch.utils.data.Subset (https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) as following:\n",
      " subset_dataset = torch.utils.data.Subset(dataset, indices)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-search statistics: 100%|██████████| 74/74 [04:23<00:00,  3.56s/it, cur=layer4.1.conv1.out_channels(512/512): 0.00] \n",
      "[num_satisfied] = 16:   0%|          | 16/5000 [00:14<1:14:05,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[best_subnet_constraints] = {'params': '9.69M', 'flops': '68.07G'}\n",
      "[pruned model] \tPrun constraints: 90%, \tLatency: 17.51 ± 0.09 ms \tAccuracy pruned: 78.55%\tFinetuned: 78.10%\n",
      "\n",
      "Profiling the following subnets from the given model: ('min', 'centroid', 'max').\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                                                             \u001b[0m\n",
      "\u001b[3m                              Profiling Results                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmin         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcentroid    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax/min ratio\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ flops        │ 7.46G        │ 21.52G       │ 71.09G       │ 9.54          │\n",
      "│ params       │ 586.60K      │ 4.60M        │ 11.16M       │ 19.03         │\n",
      "└──────────────┴──────────────┴──────────────┴──────────────┴───────────────┘\n",
      "\u001b[3m                                              \u001b[0m\n",
      "\u001b[3m            Constraints Evaluation            \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m              \u001b[0m┃\u001b[1m              \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSatisfiable \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
      "│ params       │ 8.93M        │ True         │\n",
      "└──────────────┴──────────────┴──────────────┘\n",
      "\n",
      "\n",
      "Search Space Summary:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "* conv1.out_channels                                                               [32, 64]\n",
      "  conv1.in_channels                                                                [3]\n",
      "  bn1.num_features                                                                 [32, 64]\n",
      "  layer1.depth                                                                     [2]\n",
      "* layer1.0.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn1.num_features                                                        [32, 64]\n",
      "  layer1.0.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn2.num_features                                                        [32, 64]\n",
      "* layer1.1.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn1.num_features                                                        [32, 64]\n",
      "  layer1.1.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn2.num_features                                                        [32, 64]\n",
      "  layer2.depth                                                                     [2]\n",
      "* layer2.0.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer2.0.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "* layer2.0.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.0.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.out_channels                                               [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.in_channels                                                [32, 64]\n",
      "  layer2.0.downsample.1.num_features                                               [32, 64, 96, 128]\n",
      "* layer2.1.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.1.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer3.depth                                                                     [2]\n",
      "* layer3.0.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer3.0.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.0.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.out_channels                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.in_channels                                                [32, 64, 96, 128]\n",
      "  layer3.0.downsample.1.num_features                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.1.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.depth                                                                     [2]\n",
      "* layer4.0.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.0.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv2.out_channels                                                      [512]\n",
      "  layer4.0.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.downsample.0.out_channels                                               [512]\n",
      "  layer4.0.downsample.0.in_channels                                                [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer4.1.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv1.in_channels                                                       [512]\n",
      "  layer4.1.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv2.out_channels                                                      [512]\n",
      "  layer4.1.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of configurable hparams: 11\n",
      "Total size of the search space: 6.71e+07\n",
      "Note: all constraints can be satisfied within the search space!\n",
      "\n",
      "\n",
      "Beginning pre-search estimation. If the runtime of score function is longer than a few minutes, consider subsampling the dataset used in score function. \n",
      "A PyTorch dataset can be subsampled using torch.utils.data.Subset (https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) as following:\n",
      " subset_dataset = torch.utils.data.Subset(dataset, indices)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-search statistics: 100%|██████████| 74/74 [04:08<00:00,  3.36s/it, cur=layer4.1.conv1.out_channels(512/512): 0.00]\n",
      "[num_satisfied] = 10:   0%|          | 16/5000 [00:12<1:04:53,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[best_subnet_constraints] = {'params': '8.66M', 'flops': '65.96G'}\n",
      "[pruned model] \tPrun constraints: 80%, \tLatency: 16.50 ± 0.04 ms \tAccuracy pruned: 77.54%\tFinetuned: 76.08%\n",
      "\n",
      "Profiling the following subnets from the given model: ('min', 'centroid', 'max').\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                                                             \u001b[0m\n",
      "\u001b[3m                              Profiling Results                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmin         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcentroid    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax/min ratio\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ flops        │ 7.46G        │ 21.52G       │ 71.09G       │ 9.54          │\n",
      "│ params       │ 586.60K      │ 4.60M        │ 11.16M       │ 19.03         │\n",
      "└──────────────┴──────────────┴──────────────┴──────────────┴───────────────┘\n",
      "\u001b[3m                                              \u001b[0m\n",
      "\u001b[3m            Constraints Evaluation            \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m              \u001b[0m┃\u001b[1m              \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSatisfiable \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
      "│ params       │ 7.82M        │ True         │\n",
      "└──────────────┴──────────────┴──────────────┘\n",
      "\n",
      "\n",
      "Search Space Summary:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "* conv1.out_channels                                                               [32, 64]\n",
      "  conv1.in_channels                                                                [3]\n",
      "  bn1.num_features                                                                 [32, 64]\n",
      "  layer1.depth                                                                     [2]\n",
      "* layer1.0.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn1.num_features                                                        [32, 64]\n",
      "  layer1.0.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn2.num_features                                                        [32, 64]\n",
      "* layer1.1.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn1.num_features                                                        [32, 64]\n",
      "  layer1.1.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn2.num_features                                                        [32, 64]\n",
      "  layer2.depth                                                                     [2]\n",
      "* layer2.0.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer2.0.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "* layer2.0.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.0.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.out_channels                                               [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.in_channels                                                [32, 64]\n",
      "  layer2.0.downsample.1.num_features                                               [32, 64, 96, 128]\n",
      "* layer2.1.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.1.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer3.depth                                                                     [2]\n",
      "* layer3.0.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer3.0.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.0.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.out_channels                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.in_channels                                                [32, 64, 96, 128]\n",
      "  layer3.0.downsample.1.num_features                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.1.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.depth                                                                     [2]\n",
      "* layer4.0.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.0.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv2.out_channels                                                      [512]\n",
      "  layer4.0.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.downsample.0.out_channels                                               [512]\n",
      "  layer4.0.downsample.0.in_channels                                                [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer4.1.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv1.in_channels                                                       [512]\n",
      "  layer4.1.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv2.out_channels                                                      [512]\n",
      "  layer4.1.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of configurable hparams: 11\n",
      "Total size of the search space: 6.71e+07\n",
      "Note: all constraints can be satisfied within the search space!\n",
      "\n",
      "\n",
      "Beginning pre-search estimation. If the runtime of score function is longer than a few minutes, consider subsampling the dataset used in score function. \n",
      "A PyTorch dataset can be subsampled using torch.utils.data.Subset (https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) as following:\n",
      " subset_dataset = torch.utils.data.Subset(dataset, indices)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-search statistics: 100%|██████████| 74/74 [04:15<00:00,  3.45s/it, cur=layer4.1.conv1.out_channels(512/512): 0.00] \n",
      "[num_satisfied] = 11:   0%|          | 16/5000 [00:12<1:04:30,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[best_subnet_constraints] = {'params': '7.77M', 'flops': '64.15G'}\n",
      "[pruned model] \tPrun constraints: 70%, \tLatency: 16.25 ± 0.03 ms \tAccuracy pruned: 77.34%\tFinetuned: 76.61%\n",
      "\n",
      "Profiling the following subnets from the given model: ('min', 'centroid', 'max').\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                                                             \u001b[0m\n",
      "\u001b[3m                              Profiling Results                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmin         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcentroid    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax/min ratio\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ flops        │ 7.46G        │ 21.52G       │ 71.09G       │ 9.54          │\n",
      "│ params       │ 586.60K      │ 4.60M        │ 11.16M       │ 19.03         │\n",
      "└──────────────┴──────────────┴──────────────┴──────────────┴───────────────┘\n",
      "\u001b[3m                                              \u001b[0m\n",
      "\u001b[3m            Constraints Evaluation            \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m              \u001b[0m┃\u001b[1m              \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSatisfiable \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
      "│ params       │ 6.70M        │ True         │\n",
      "└──────────────┴──────────────┴──────────────┘\n",
      "\n",
      "\n",
      "Search Space Summary:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "* conv1.out_channels                                                               [32, 64]\n",
      "  conv1.in_channels                                                                [3]\n",
      "  bn1.num_features                                                                 [32, 64]\n",
      "  layer1.depth                                                                     [2]\n",
      "* layer1.0.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn1.num_features                                                        [32, 64]\n",
      "  layer1.0.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn2.num_features                                                        [32, 64]\n",
      "* layer1.1.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn1.num_features                                                        [32, 64]\n",
      "  layer1.1.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn2.num_features                                                        [32, 64]\n",
      "  layer2.depth                                                                     [2]\n",
      "* layer2.0.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer2.0.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "* layer2.0.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.0.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.out_channels                                               [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.in_channels                                                [32, 64]\n",
      "  layer2.0.downsample.1.num_features                                               [32, 64, 96, 128]\n",
      "* layer2.1.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.1.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer3.depth                                                                     [2]\n",
      "* layer3.0.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer3.0.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.0.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.out_channels                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.in_channels                                                [32, 64, 96, 128]\n",
      "  layer3.0.downsample.1.num_features                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.1.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.depth                                                                     [2]\n",
      "* layer4.0.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.0.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv2.out_channels                                                      [512]\n",
      "  layer4.0.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.downsample.0.out_channels                                               [512]\n",
      "  layer4.0.downsample.0.in_channels                                                [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer4.1.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv1.in_channels                                                       [512]\n",
      "  layer4.1.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv2.out_channels                                                      [512]\n",
      "  layer4.1.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of configurable hparams: 11\n",
      "Total size of the search space: 6.71e+07\n",
      "Note: all constraints can be satisfied within the search space!\n",
      "\n",
      "\n",
      "Beginning pre-search estimation. If the runtime of score function is longer than a few minutes, consider subsampling the dataset used in score function. \n",
      "A PyTorch dataset can be subsampled using torch.utils.data.Subset (https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) as following:\n",
      " subset_dataset = torch.utils.data.Subset(dataset, indices)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-search statistics: 100%|██████████| 74/74 [04:10<00:00,  3.38s/it, cur=layer4.1.conv1.out_channels(512/512): 0.00] \n",
      "[num_satisfied] = 11:   0%|          | 16/5000 [00:12<1:03:15,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[best_subnet_constraints] = {'params': '6.41M', 'flops': '60.68G'}\n",
      "[pruned model] \tPrun constraints: 60%, \tLatency: 16.47 ± 0.04 ms \tAccuracy pruned: 74.26%\tFinetuned: 67.26%\n",
      "\n",
      "Profiling the following subnets from the given model: ('min', 'centroid', 'max').\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                                                             \u001b[0m\n",
      "\u001b[3m                              Profiling Results                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmin         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcentroid    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax/min ratio\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ flops        │ 7.46G        │ 21.52G       │ 71.09G       │ 9.54          │\n",
      "│ params       │ 586.60K      │ 4.60M        │ 11.16M       │ 19.03         │\n",
      "└──────────────┴──────────────┴──────────────┴──────────────┴───────────────┘\n",
      "\u001b[3m                                              \u001b[0m\n",
      "\u001b[3m            Constraints Evaluation            \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m              \u001b[0m┃\u001b[1m              \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSatisfiable \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
      "│ params       │ 5.58M        │ True         │\n",
      "└──────────────┴──────────────┴──────────────┘\n",
      "\n",
      "\n",
      "Search Space Summary:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "* conv1.out_channels                                                               [32, 64]\n",
      "  conv1.in_channels                                                                [3]\n",
      "  bn1.num_features                                                                 [32, 64]\n",
      "  layer1.depth                                                                     [2]\n",
      "* layer1.0.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn1.num_features                                                        [32, 64]\n",
      "  layer1.0.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn2.num_features                                                        [32, 64]\n",
      "* layer1.1.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn1.num_features                                                        [32, 64]\n",
      "  layer1.1.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn2.num_features                                                        [32, 64]\n",
      "  layer2.depth                                                                     [2]\n",
      "* layer2.0.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer2.0.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "* layer2.0.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.0.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.out_channels                                               [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.in_channels                                                [32, 64]\n",
      "  layer2.0.downsample.1.num_features                                               [32, 64, 96, 128]\n",
      "* layer2.1.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.1.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer3.depth                                                                     [2]\n",
      "* layer3.0.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer3.0.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.0.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.out_channels                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.in_channels                                                [32, 64, 96, 128]\n",
      "  layer3.0.downsample.1.num_features                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.1.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.depth                                                                     [2]\n",
      "* layer4.0.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.0.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv2.out_channels                                                      [512]\n",
      "  layer4.0.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.downsample.0.out_channels                                               [512]\n",
      "  layer4.0.downsample.0.in_channels                                                [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer4.1.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv1.in_channels                                                       [512]\n",
      "  layer4.1.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv2.out_channels                                                      [512]\n",
      "  layer4.1.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of configurable hparams: 11\n",
      "Total size of the search space: 6.71e+07\n",
      "Note: all constraints can be satisfied within the search space!\n",
      "\n",
      "\n",
      "Beginning pre-search estimation. If the runtime of score function is longer than a few minutes, consider subsampling the dataset used in score function. \n",
      "A PyTorch dataset can be subsampled using torch.utils.data.Subset (https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) as following:\n",
      " subset_dataset = torch.utils.data.Subset(dataset, indices)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-search statistics: 100%|██████████| 74/74 [04:08<00:00,  3.36s/it, cur=layer4.1.conv1.out_channels(512/512): 0.00] \n",
      "[num_satisfied] = 10:   0%|          | 16/5000 [00:13<1:11:16,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[best_subnet_constraints] = {'params': '5.52M', 'flops': '57.96G'}\n",
      "[pruned model] \tPrun constraints: 50%, \tLatency: 15.41 ± 0.03 ms \tAccuracy pruned: 69.86%\tFinetuned: 69.02%\n",
      "\n",
      "Profiling the following subnets from the given model: ('min', 'centroid', 'max').\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                                                             \u001b[0m\n",
      "\u001b[3m                              Profiling Results                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmin         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcentroid    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax/min ratio\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ flops        │ 7.46G        │ 21.52G       │ 71.09G       │ 9.54          │\n",
      "│ params       │ 586.60K      │ 4.60M        │ 11.16M       │ 19.03         │\n",
      "└──────────────┴──────────────┴──────────────┴──────────────┴───────────────┘\n",
      "\u001b[3m                                              \u001b[0m\n",
      "\u001b[3m            Constraints Evaluation            \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m              \u001b[0m┃\u001b[1m              \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSatisfiable \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
      "│ params       │ 4.47M        │ True         │\n",
      "└──────────────┴──────────────┴──────────────┘\n",
      "\n",
      "\n",
      "Search Space Summary:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "* conv1.out_channels                                                               [32, 64]\n",
      "  conv1.in_channels                                                                [3]\n",
      "  bn1.num_features                                                                 [32, 64]\n",
      "  layer1.depth                                                                     [2]\n",
      "* layer1.0.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn1.num_features                                                        [32, 64]\n",
      "  layer1.0.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn2.num_features                                                        [32, 64]\n",
      "* layer1.1.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn1.num_features                                                        [32, 64]\n",
      "  layer1.1.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn2.num_features                                                        [32, 64]\n",
      "  layer2.depth                                                                     [2]\n",
      "* layer2.0.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer2.0.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "* layer2.0.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.0.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.out_channels                                               [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.in_channels                                                [32, 64]\n",
      "  layer2.0.downsample.1.num_features                                               [32, 64, 96, 128]\n",
      "* layer2.1.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.1.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer3.depth                                                                     [2]\n",
      "* layer3.0.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer3.0.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.0.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.out_channels                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.in_channels                                                [32, 64, 96, 128]\n",
      "  layer3.0.downsample.1.num_features                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.1.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.depth                                                                     [2]\n",
      "* layer4.0.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.0.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv2.out_channels                                                      [512]\n",
      "  layer4.0.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.downsample.0.out_channels                                               [512]\n",
      "  layer4.0.downsample.0.in_channels                                                [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer4.1.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv1.in_channels                                                       [512]\n",
      "  layer4.1.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv2.out_channels                                                      [512]\n",
      "  layer4.1.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of configurable hparams: 11\n",
      "Total size of the search space: 6.71e+07\n",
      "Note: all constraints can be satisfied within the search space!\n",
      "\n",
      "\n",
      "Beginning pre-search estimation. If the runtime of score function is longer than a few minutes, consider subsampling the dataset used in score function. \n",
      "A PyTorch dataset can be subsampled using torch.utils.data.Subset (https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) as following:\n",
      " subset_dataset = torch.utils.data.Subset(dataset, indices)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-search statistics: 100%|██████████| 74/74 [04:05<00:00,  3.31s/it, cur=layer4.1.conv1.out_channels(512/512): 0.00]\n",
      "[num_satisfied] = 10:   0%|          | 16/5000 [00:12<1:03:22,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[best_subnet_constraints] = {'params': '4.39M', 'flops': '53.17G'}\n",
      "[pruned model] \tPrun constraints: 40%, \tLatency: 14.81 ± 0.02 ms \tAccuracy pruned: 55.97%\tFinetuned: 71.66%\n",
      "\n",
      "Profiling the following subnets from the given model: ('min', 'centroid', 'max').\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                                                             \u001b[0m\n",
      "\u001b[3m                              Profiling Results                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmin         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcentroid    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax/min ratio\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ flops        │ 7.46G        │ 21.52G       │ 71.09G       │ 9.54          │\n",
      "│ params       │ 586.60K      │ 4.60M        │ 11.16M       │ 19.03         │\n",
      "└──────────────┴──────────────┴──────────────┴──────────────┴───────────────┘\n",
      "\u001b[3m                                              \u001b[0m\n",
      "\u001b[3m            Constraints Evaluation            \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m              \u001b[0m┃\u001b[1m              \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSatisfiable \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
      "│ params       │ 3.35M        │ True         │\n",
      "└──────────────┴──────────────┴──────────────┘\n",
      "\n",
      "\n",
      "Search Space Summary:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "* conv1.out_channels                                                               [32, 64]\n",
      "  conv1.in_channels                                                                [3]\n",
      "  bn1.num_features                                                                 [32, 64]\n",
      "  layer1.depth                                                                     [2]\n",
      "* layer1.0.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn1.num_features                                                        [32, 64]\n",
      "  layer1.0.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn2.num_features                                                        [32, 64]\n",
      "* layer1.1.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn1.num_features                                                        [32, 64]\n",
      "  layer1.1.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn2.num_features                                                        [32, 64]\n",
      "  layer2.depth                                                                     [2]\n",
      "* layer2.0.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer2.0.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "* layer2.0.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.0.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.out_channels                                               [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.in_channels                                                [32, 64]\n",
      "  layer2.0.downsample.1.num_features                                               [32, 64, 96, 128]\n",
      "* layer2.1.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.1.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer3.depth                                                                     [2]\n",
      "* layer3.0.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer3.0.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.0.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.out_channels                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.in_channels                                                [32, 64, 96, 128]\n",
      "  layer3.0.downsample.1.num_features                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.1.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.depth                                                                     [2]\n",
      "* layer4.0.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.0.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv2.out_channels                                                      [512]\n",
      "  layer4.0.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.downsample.0.out_channels                                               [512]\n",
      "  layer4.0.downsample.0.in_channels                                                [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer4.1.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv1.in_channels                                                       [512]\n",
      "  layer4.1.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv2.out_channels                                                      [512]\n",
      "  layer4.1.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of configurable hparams: 11\n",
      "Total size of the search space: 6.71e+07\n",
      "Note: all constraints can be satisfied within the search space!\n",
      "\n",
      "\n",
      "Beginning pre-search estimation. If the runtime of score function is longer than a few minutes, consider subsampling the dataset used in score function. \n",
      "A PyTorch dataset can be subsampled using torch.utils.data.Subset (https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) as following:\n",
      " subset_dataset = torch.utils.data.Subset(dataset, indices)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-search statistics: 100%|██████████| 74/74 [04:14<00:00,  3.44s/it, cur=layer4.1.conv1.out_channels(512/512): 0.00] \n",
      "[num_satisfied] = 8:   0%|          | 16/5000 [00:11<1:00:09,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[best_subnet_constraints] = {'params': '3.28M', 'flops': '45.36G'}\n",
      "[pruned model] \tPrun constraints: 30%, \tLatency: 18.69 ± 0.04 ms \tAccuracy pruned: 38.84%\tFinetuned: 72.00%\n",
      "\n",
      "Profiling the following subnets from the given model: ('min', 'centroid', 'max').\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                                                             \u001b[0m\n",
      "\u001b[3m                              Profiling Results                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmin         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcentroid    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax/min ratio\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ flops        │ 7.46G        │ 21.52G       │ 71.09G       │ 9.54          │\n",
      "│ params       │ 586.60K      │ 4.60M        │ 11.16M       │ 19.03         │\n",
      "└──────────────┴──────────────┴──────────────┴──────────────┴───────────────┘\n",
      "\u001b[3m                                              \u001b[0m\n",
      "\u001b[3m            Constraints Evaluation            \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m              \u001b[0m┃\u001b[1m              \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSatisfiable \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
      "│ params       │ 2.23M        │ True         │\n",
      "└──────────────┴──────────────┴──────────────┘\n",
      "\n",
      "\n",
      "Search Space Summary:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "* conv1.out_channels                                                               [32, 64]\n",
      "  conv1.in_channels                                                                [3]\n",
      "  bn1.num_features                                                                 [32, 64]\n",
      "  layer1.depth                                                                     [2]\n",
      "* layer1.0.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn1.num_features                                                        [32, 64]\n",
      "  layer1.0.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn2.num_features                                                        [32, 64]\n",
      "* layer1.1.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn1.num_features                                                        [32, 64]\n",
      "  layer1.1.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn2.num_features                                                        [32, 64]\n",
      "  layer2.depth                                                                     [2]\n",
      "* layer2.0.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer2.0.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "* layer2.0.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.0.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.out_channels                                               [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.in_channels                                                [32, 64]\n",
      "  layer2.0.downsample.1.num_features                                               [32, 64, 96, 128]\n",
      "* layer2.1.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.1.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer3.depth                                                                     [2]\n",
      "* layer3.0.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer3.0.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.0.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.out_channels                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.in_channels                                                [32, 64, 96, 128]\n",
      "  layer3.0.downsample.1.num_features                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.1.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.depth                                                                     [2]\n",
      "* layer4.0.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.0.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv2.out_channels                                                      [512]\n",
      "  layer4.0.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.downsample.0.out_channels                                               [512]\n",
      "  layer4.0.downsample.0.in_channels                                                [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer4.1.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv1.in_channels                                                       [512]\n",
      "  layer4.1.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv2.out_channels                                                      [512]\n",
      "  layer4.1.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of configurable hparams: 11\n",
      "Total size of the search space: 6.71e+07\n",
      "Note: all constraints can be satisfied within the search space!\n",
      "\n",
      "\n",
      "Beginning pre-search estimation. If the runtime of score function is longer than a few minutes, consider subsampling the dataset used in score function. \n",
      "A PyTorch dataset can be subsampled using torch.utils.data.Subset (https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) as following:\n",
      " subset_dataset = torch.utils.data.Subset(dataset, indices)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-search statistics: 100%|██████████| 74/74 [04:06<00:00,  3.33s/it, cur=layer4.1.conv1.out_channels(512/512): 0.00] \n",
      "[num_satisfied] = 9:   0%|          | 16/5000 [00:09<51:45,  1.61it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[best_subnet_constraints] = {'params': '2.18M', 'flops': '40.99G'}\n",
      "[pruned model] \tPrun constraints: 20%, \tLatency: 17.29 ± 0.06 ms \tAccuracy pruned: 32.16%\tFinetuned: 72.17%\n",
      "\n",
      "Profiling the following subnets from the given model: ('min', 'centroid', 'max').\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                                                             \u001b[0m\n",
      "\u001b[3m                              Profiling Results                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmin         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcentroid    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax/min ratio\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ flops        │ 7.46G        │ 21.52G       │ 71.09G       │ 9.54          │\n",
      "│ params       │ 586.60K      │ 4.60M        │ 11.16M       │ 19.03         │\n",
      "└──────────────┴──────────────┴──────────────┴──────────────┴───────────────┘\n",
      "\u001b[3m                                              \u001b[0m\n",
      "\u001b[3m            Constraints Evaluation            \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m              \u001b[0m┃\u001b[1m              \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSatisfiable \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
      "│ params       │ 1.12M        │ True         │\n",
      "└──────────────┴──────────────┴──────────────┘\n",
      "\n",
      "\n",
      "Search Space Summary:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "* conv1.out_channels                                                               [32, 64]\n",
      "  conv1.in_channels                                                                [3]\n",
      "  bn1.num_features                                                                 [32, 64]\n",
      "  layer1.depth                                                                     [2]\n",
      "* layer1.0.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn1.num_features                                                        [32, 64]\n",
      "  layer1.0.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn2.num_features                                                        [32, 64]\n",
      "* layer1.1.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn1.num_features                                                        [32, 64]\n",
      "  layer1.1.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn2.num_features                                                        [32, 64]\n",
      "  layer2.depth                                                                     [2]\n",
      "* layer2.0.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer2.0.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "* layer2.0.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.0.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.out_channels                                               [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.in_channels                                                [32, 64]\n",
      "  layer2.0.downsample.1.num_features                                               [32, 64, 96, 128]\n",
      "* layer2.1.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.1.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer3.depth                                                                     [2]\n",
      "* layer3.0.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer3.0.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.0.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.out_channels                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.in_channels                                                [32, 64, 96, 128]\n",
      "  layer3.0.downsample.1.num_features                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.1.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.depth                                                                     [2]\n",
      "* layer4.0.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.0.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv2.out_channels                                                      [512]\n",
      "  layer4.0.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.downsample.0.out_channels                                               [512]\n",
      "  layer4.0.downsample.0.in_channels                                                [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer4.1.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv1.in_channels                                                       [512]\n",
      "  layer4.1.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv2.out_channels                                                      [512]\n",
      "  layer4.1.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of configurable hparams: 11\n",
      "Total size of the search space: 6.71e+07\n",
      "Note: all constraints can be satisfied within the search space!\n",
      "\n",
      "\n",
      "Beginning pre-search estimation. If the runtime of score function is longer than a few minutes, consider subsampling the dataset used in score function. \n",
      "A PyTorch dataset can be subsampled using torch.utils.data.Subset (https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) as following:\n",
      " subset_dataset = torch.utils.data.Subset(dataset, indices)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-search statistics: 100%|██████████| 74/74 [04:11<00:00,  3.39s/it, cur=layer4.1.conv1.out_channels(512/512): 0.00] \n",
      "[num_satisfied] = 9:   0%|          | 16/5000 [00:06<33:27,  2.48it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[best_subnet_constraints] = {'params': '1.04M', 'flops': '19.39G'}\n",
      "[pruned model] \tPrun constraints: 10%, \tLatency: 13.73 ± 0.03 ms \tAccuracy pruned: 10.82%\tFinetuned: 73.66%\n",
      "\n",
      "Profiling the following subnets from the given model: ('min', 'centroid', 'max').\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                                                             \u001b[0m\n",
      "\u001b[3m                              Profiling Results                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmin         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcentroid    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmax/min ratio\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ flops        │ 7.46G        │ 21.52G       │ 71.09G       │ 9.54          │\n",
      "│ params       │ 586.60K      │ 4.60M        │ 11.16M       │ 19.03         │\n",
      "└──────────────┴──────────────┴──────────────┴──────────────┴───────────────┘\n",
      "\u001b[3m                                              \u001b[0m\n",
      "\u001b[3m            Constraints Evaluation            \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m              \u001b[0m┃\u001b[1m              \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSatisfiable \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┃\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
      "│ params       │ 0.00         │ False        │\n",
      "└──────────────┴──────────────┴──────────────┘\n",
      "\n",
      "\n",
      "Search Space Summary:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "* conv1.out_channels                                                               [32, 64]\n",
      "  conv1.in_channels                                                                [3]\n",
      "  bn1.num_features                                                                 [32, 64]\n",
      "  layer1.depth                                                                     [2]\n",
      "* layer1.0.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn1.num_features                                                        [32, 64]\n",
      "  layer1.0.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.0.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.0.bn2.num_features                                                        [32, 64]\n",
      "* layer1.1.conv1.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv1.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn1.num_features                                                        [32, 64]\n",
      "  layer1.1.conv2.out_channels                                                      [32, 64]\n",
      "  layer1.1.conv2.in_channels                                                       [32, 64]\n",
      "  layer1.1.bn2.num_features                                                        [32, 64]\n",
      "  layer2.depth                                                                     [2]\n",
      "* layer2.0.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv1.in_channels                                                       [32, 64]\n",
      "  layer2.0.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "* layer2.0.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.0.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.0.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.out_channels                                               [32, 64, 96, 128]\n",
      "  layer2.0.downsample.0.in_channels                                                [32, 64]\n",
      "  layer2.0.downsample.1.num_features                                               [32, 64, 96, 128]\n",
      "* layer2.1.conv1.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn1.num_features                                                        [32, 64, 96, 128]\n",
      "  layer2.1.conv2.out_channels                                                      [32, 64, 96, 128]\n",
      "  layer2.1.conv2.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer2.1.bn2.num_features                                                        [32, 64, 96, 128]\n",
      "  layer3.depth                                                                     [2]\n",
      "* layer3.0.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv1.in_channels                                                       [32, 64, 96, 128]\n",
      "  layer3.0.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.0.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.out_channels                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.0.downsample.0.in_channels                                                [32, 64, 96, 128]\n",
      "  layer3.0.downsample.1.num_features                                               [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer3.1.conv1.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn1.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.out_channels                                                      [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.conv2.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer3.1.bn2.num_features                                                        [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.depth                                                                     [2]\n",
      "* layer4.0.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv1.in_channels                                                       [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "  layer4.0.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.conv2.out_channels                                                      [512]\n",
      "  layer4.0.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.0.downsample.0.out_channels                                               [512]\n",
      "  layer4.0.downsample.0.in_channels                                                [32, 64, 96, 128, 160, 192, 224, 256]\n",
      "* layer4.1.conv1.out_channels                                                      [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv1.in_channels                                                       [512]\n",
      "  layer4.1.bn1.num_features                                                        [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "  layer4.1.conv2.out_channels                                                      [512]\n",
      "  layer4.1.conv2.in_channels                                                       [32, 64, 96, 128, '...', 416, 448, 480, 512]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of configurable hparams: 11\n",
      "Total size of the search space: 6.71e+07\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "NOT all constraints can be satisfied within the search space, see above!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterative_steps):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# prune\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     prune_constraints \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m(\u001b[38;5;28miter\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m----> 5\u001b[0m     pruned_model, prune_res \u001b[38;5;241m=\u001b[39m \u001b[43mmtp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_model\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfastnas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprune_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_loader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# training data is used for calibrating BN layers\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore_func\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# validation score is used to rank the subnets\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# checkpoint to store the search state and resume or re-run the search with different constraint\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodelopt_fastnas_search_checkpoint_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43miter\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# evaluate after prune\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     acc_before \u001b[38;5;241m=\u001b[39m evaluate(pruned_model)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/modelopt/torch/prune/pruning.py:206\u001b[0m, in \u001b[0;36mprune\u001b[0;34m(model, mode, constraints, dummy_input, config)\u001b[0m\n\u001b[1;32m    203\u001b[0m model \u001b[38;5;241m=\u001b[39m apply_mode(model, mode, registry\u001b[38;5;241m=\u001b[39mPruneModeRegistry)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# now run the search and return the result\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmtn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/modelopt/torch/nas/algorithms.py:198\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(model, constraints, dummy_input, config)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# run search, select best, and get config, metric, constraint of search result\u001b[39;00m\n\u001b[1;32m    196\u001b[0m searcher \u001b[38;5;241m=\u001b[39m searcher_cls()\n\u001b[0;32m--> 198\u001b[0m \u001b[43msearcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# export model in-place\u001b[39;00m\n\u001b[1;32m    201\u001b[0m model \u001b[38;5;241m=\u001b[39m export(model)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/modelopt/torch/opt/searcher.py:150\u001b[0m, in \u001b[0;36mBaseSearcher.search\u001b[0;34m(self, model, constraints, dummy_input, config)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_search_checkpoint()\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# run initial step and sanity checks before the search\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# run actual search\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_search()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/modelopt/torch/prune/fastnas.py:91\u001b[0m, in \u001b[0;36mBinarySearcher.before_search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build sensitivity map before search that we use to approximate the cost function.\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# run super method\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# sort parameters in model\u001b[39;00m\n\u001b[1;32m     94\u001b[0m sort_parameters(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/modelopt/torch/nas/autonas.py:276\u001b[0m, in \u001b[0;36mIterativeSearcher.before_search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# do a sanity check and profile the constraints\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# This way we also fill up the interpolation table for latency with min, centroid, max!\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m profile  \u001b[38;5;66;03m# TODO: hack until we refactor files\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m \u001b[43mprofile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstraints_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_centroid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/modelopt/torch/nas/algorithms.py:448\u001b[0m, in \u001b[0;36mprofile\u001b[0;34m(model, dummy_input, constraints, deployment, strict, verbose, use_centroid)\u001b[0m\n\u001b[1;32m    446\u001b[0m warn_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT all constraints can be satisfied within the search space, see above!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strict:\n\u001b[0;32m--> 448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(warn_msg)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    450\u001b[0m     _print(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwarn_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, verb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: NOT all constraints can be satisfied within the search space, see above!"
     ]
    }
   ],
   "source": [
    "for iter in range(iterative_steps):\n",
    "    # prune\n",
    "    prune_constraints = {\"params\": f\"{100 - (iter+1)*10}%\"}\n",
    "\n",
    "    pruned_model, prune_res = mtp.prune(\n",
    "        model=copy.deepcopy(full_model).to(device),\n",
    "        mode=\"fastnas\",\n",
    "        constraints=prune_constraints,\n",
    "        dummy_input=example_input,\n",
    "        config={\n",
    "            \"data_loader\": train_loader,  # training data is used for calibrating BN layers\n",
    "            \"score_func\": evaluate,  # validation score is used to rank the subnets\n",
    "            # checkpoint to store the search state and resume or re-run the search with different constraint\n",
    "            \"checkpoint\": f\"modelopt_fastnas_search_checkpoint_{iter}.pth\",\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    # evaluate after prune\n",
    "    acc_before = evaluate(pruned_model)\n",
    "    # fine-tune pruned model\n",
    "    train(pruned_model, train_loader, epochs=1, save_path=f\"pruned_model_mtp_{iter}.pth\", silent=True)\n",
    "    # evaluate after fine-tune\n",
    "    acc_after = evaluate(pruned_model)\n",
    "    latency_mu, latency_std = estimate_latency(pruned_model, example_input)\n",
    "    current_pruning_ratio = 1 / iterative_steps * (iter + 1)\n",
    "    print(f\"[pruned model] \\tPrun constraints: {prune_constraints['params']}, \\tLatency: {latency_mu:.2f} ± {latency_std:.2f} ms \\tAccuracy pruned: {acc_before*100:.2f}%\\tFinetuned: {acc_after*100:.2f}%\")\n",
    "\n",
    "    mto.save(pruned_model, f\"modelopt_pruned_model_iter_{iter}.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c73a7-e86b-4a0e-bd72-505b55b0f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune\n",
    "prune_constraints = {\"params\": \"1%\"}\n",
    "\n",
    "pruned_model, prune_res = mtp.prune(\n",
    "    model=copy.deepcopy(full_model).to(device),\n",
    "    mode=\"fastnas\",\n",
    "    constraints=prune_constraints,\n",
    "    dummy_input=example_input,\n",
    "    config={\n",
    "        \"data_loader\": train_loader,  # training data is used for calibrating BN layers\n",
    "        \"score_func\": evaluate,  # validation score is used to rank the subnets\n",
    "        # checkpoint to store the search state and resume or re-run the search with different constraint\n",
    "        \"checkpoint\": f\"modelopt_fastnas_search_checkpoint_9.pth\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# evaluate after prune\n",
    "acc_before = evaluate(pruned_model)\n",
    "# fine-tune pruned model\n",
    "train(pruned_model, train_loader, epochs=1, save_path=f\"pruned_model_mtp_9.pth\", silent=True)\n",
    "# evaluate after fine-tune\n",
    "acc_after = evaluate(pruned_model)\n",
    "latency_mu, latency_std = estimate_latency(pruned_model, example_input)\n",
    "current_pruning_ratio = 1 / iterative_steps * (iter + 1)\n",
    "print(f\"[pruned model] \\tPrun constraints: {prune_constraints['params']}, \\tLatency: {latency_mu:.2f} ± {latency_std:.2f} ms \\tAccuracy pruned: {acc_before*100:.2f}%\\tFinetuned: {acc_after*100:.2f}%\")\n",
    "\n",
    "mto.save(pruned_model, f\"modelopt_pruned_model_iter_{iter}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8n3xnrGJrI6O",
   "metadata": {
    "id": "8n3xnrGJrI6O"
   },
   "source": [
    "## Extra fine-tune last pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60JXuq3ZWJQh",
   "metadata": {
    "id": "60JXuq3ZWJQh"
   },
   "outputs": [],
   "source": [
    "train(pruned_model, train_loader, epochs=5, save_path=f\"pruned_model_final_tuning.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HO3Sz_XQW0Eq",
   "metadata": {
    "id": "HO3Sz_XQW0Eq"
   },
   "outputs": [],
   "source": [
    "accuracy_final = evaluate(pruned_model)\n",
    "print(f\"Pruned extra fine-tuned model accuracy: {accuracy_final*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a449f62-8f30-4a1c-b35c-a2d4021db3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bfde50-4d68-46dd-a988-2e5ac5861b18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
