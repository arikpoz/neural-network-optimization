{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d65c0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader, random_split\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f9d597",
   "metadata": {},
   "source": [
    "### Get device. CUDA if available, CPU otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc503083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(silent=False):\n",
    "    \"\"\"\n",
    "    Returns the device to be used for PyTorch operations.\n",
    "    If a GPU is available, it returns 'cuda', otherwise it returns 'cpu'.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if not silent:\n",
    "        print(f\"Using device: {device}\")\n",
    "    \n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc9aea0",
   "metadata": {},
   "source": [
    "### Get CIFAR-10 data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar10_loaders(train_ratio=0.9, train_batch_size=128, test_batch_size=128, silent=False):\n",
    "    \"\"\"\n",
    "    Returns the CIFAR-10 dataset loaders for training, validation and testing.\n",
    "    The training set is shuffled, while the test set is not.\n",
    "\n",
    "    reference: Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009.\n",
    "    \"\"\"\n",
    "\n",
    "    # define transform for CIFAR-10 dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.49139968, 0.48215827, 0.44653124],  # CIFAR-10 means\n",
    "                             std  = [0.24703233, 0.24348505, 0.26158768])  # CIFAR-10 stds\n",
    "    ])\n",
    "  \n",
    "    # load full CIFAR-10 train set\n",
    "    full_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    # calculate split sizes for train and validation sets\n",
    "    train_size = int(train_ratio * len(full_trainset))\n",
    "    val_size = len(full_trainset) - train_size\n",
    "\n",
    "    # perform split\n",
    "    train_subset, val_subset = random_split(full_trainset, [train_size, val_size])\n",
    "        \n",
    "    # create DataLoaders\n",
    "    train_loader = DataLoader(train_subset, batch_size=train_batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=train_batch_size, shuffle=False)\n",
    "\n",
    "    # CIFAR-10 test set and loader for accuracy evaluation\n",
    "    test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    if not silent:\n",
    "        print(f\"Full train set size: {len(full_trainset)}\")\n",
    "        print(f\"Train ratio: {train_ratio}\")\n",
    "        print(f\"Train samples: {len(train_subset)}\")\n",
    "        print(f\"Validation samples: {len(val_subset)}\")\n",
    "        print(f\"Test samples: {len(test_set)}\") \n",
    "        print(f\"Number of training batches: {len(train_loader)}\")\n",
    "        print(f\"Number of validation batches: {len(val_loader)}\")\n",
    "        print(f\"Number of test batches: {len(test_loader)}\")\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fdb443",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e205de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet50_for_cifar10(device=None):\n",
    "    \"\"\"\n",
    "    Returns a modified ResNet-50 model for CIFAR-10 classification.\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = get_device(silent=True)\n",
    "\n",
    "    model = models.resnet50(weights=None, num_classes=10)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c62b63",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8589ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device,\n",
    "    epochs,\n",
    "    scheduler=None,\n",
    "    grad_clip=None,\n",
    "    save_path=\"best_model.pt\",\n",
    "    early_stopping_patience=5,\n",
    "    resume=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains the model using the provided data loaders, optimizer, and loss function.\n",
    "    Supports early stopping and model checkpointing.\n",
    "    \"\"\"\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    # Optional resume\n",
    "    if resume and os.path.exists(save_path):\n",
    "        checkpoint = torch.load(save_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "        if \"scheduler_state\" in checkpoint and scheduler:\n",
    "            scheduler.load_state_dict(checkpoint[\"scheduler_state\"])\n",
    "        best_val_loss = checkpoint.get(\"best_val_loss\", best_val_loss)\n",
    "        start_epoch = checkpoint.get(\"epoch\", 0) + 1\n",
    "        print(f\"üîÅ Resumed training from epoch {start_epoch}\")\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        train_loop = tqdm(train_loader, desc=f\"[Epoch {epoch+1}/{epochs}]\", leave=False)\n",
    "        for inputs, targets in train_loop:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            if grad_clip is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.detach()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            total_correct += (preds == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_accuracy = total_correct / total_samples\n",
    "        tqdm.write(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss.item():.4f} | Acc: {train_accuracy:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                val_loss += loss.detach()\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                val_correct += (preds == targets).sum().item()\n",
    "                val_samples += targets.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = val_correct / val_samples\n",
    "        tqdm.write(f\"          | Val   Loss: {avg_val_loss.item():.4f} | Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Scheduler step\n",
    "        if scheduler is not None:\n",
    "            try:\n",
    "                scheduler.step(avg_val_loss)  # for ReduceLROnPlateau\n",
    "            except TypeError:\n",
    "                scheduler.step()\n",
    "\n",
    "        # Early stopping + checkpoint\n",
    "        if avg_val_loss.item() < best_val_loss:\n",
    "            best_val_loss = avg_val_loss.item()\n",
    "            epochs_without_improvement = 0\n",
    "            torch.save({\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"scheduler_state\": scheduler.state_dict() if scheduler else None,\n",
    "                \"best_val_loss\": best_val_loss,\n",
    "                \"epoch\": epoch,\n",
    "            }, save_path)\n",
    "            tqdm.write(f\"          | ‚úÖ New best model saved to '{save_path}'\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            tqdm.write(f\"          | No improvement for {epochs_without_improvement} epoch(s)\")\n",
    "\n",
    "        if epochs_without_improvement >= early_stopping_patience:\n",
    "            tqdm.write(f\"üõë Early stopping triggered after {early_stopping_patience} epochs without improvement.\")\n",
    "            break\n",
    "\n",
    "    print(\"Training complete.\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b8394d",
   "metadata": {},
   "source": [
    "### Evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d057d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test set and returns the accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "                \n",
    "    acc = correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550ff6e5",
   "metadata": {},
   "source": [
    "### Measure Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa37af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    \"\"\"\n",
    "    A simple timer class to measure the time taken for operations.\n",
    "    It uses CUDA events if a GPU is available, otherwise it uses time.time().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.use_cuda = self.torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.starter = self.torch.cuda.Event(enable_timing=True)\n",
    "            self.ender = self.torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    def start(self):\n",
    "        if self.use_cuda:\n",
    "            self.starter.record()\n",
    "        else:\n",
    "            self.start_time = self.time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        if self.use_cuda:\n",
    "            self.ender.record()\n",
    "            self.torch.cuda.synchronize()\n",
    "            return self.starter.elapsed_time(self.ender)  # ms\n",
    "        else:\n",
    "            return (self.time.time() - self.start_time) * 1000  # ms\n",
    "\n",
    "def estimate_latency(model, example_inputs, repetitions=50):\n",
    "    \"\"\"\n",
    "    Estimates the latency of the model by running it on example inputs multiple times.\n",
    "    Returns the mean and standard deviation of the latencies.\n",
    "    \"\"\"\n",
    "\n",
    "    timer = Timer()\n",
    "    timings = np.zeros((repetitions, 1))\n",
    "\n",
    "    # warm-up\n",
    "    for _ in range(5):\n",
    "        _ = model(example_inputs)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # measure latency\n",
    "        for rep in tqdm(range(repetitions), desc=\"Measuring latency\"):\n",
    "            timer.start()\n",
    "            _ = model(example_inputs)\n",
    "            elapsed = timer.stop()\n",
    "            timings[rep] = elapsed\n",
    "\n",
    "    return np.mean(timings), np.std(timings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa1591e",
   "metadata": {},
   "source": [
    "### Measure size of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee023c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_size(model):\n",
    "    \"\"\"\n",
    "    Returns the size of the model in MB.\n",
    "    \"\"\"\n",
    "\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size = os.path.getsize(\"temp.p\") / 1e6\n",
    "    os.remove(\"temp.p\")\n",
    "    return size\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
