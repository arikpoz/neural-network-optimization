{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22bb942b",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ac085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source for utlity functions:\n",
    "# - get_device \n",
    "# - get_cifar10_loaders\n",
    "# - get_resnet50_for_cifar10\n",
    "# - train\n",
    "# - evaluate\n",
    "# - estimate_latency\n",
    "# - get_size\n",
    "%run utils.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81c85c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8815b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6319037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the CIFAR-10 data loaders\n",
    "train_loader, val_loader, test_loader = get_cifar10_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a74380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get architecture for CIFAR-10 training\n",
    "model = get_resnet50_for_cifar10(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaaa880-68cf-479c-aded-fdf83de0e643",
   "metadata": {},
   "source": [
    "## Train and Evaluate full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a1309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already trained. Loading from full_model_resnet50.pth\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device,\n",
    "    epochs=50,\n",
    "    scheduler=scheduler,\n",
    "    grad_clip=1.0,\n",
    "    save_path=\"full_model_resnet50_best_model.pt\",\n",
    "    early_stopping_patience=5,\n",
    "    resume=True,\n",
    ")\n",
    "\n",
    "# Save the fine-tuned original model\n",
    "original_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f139fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compress layers\n",
    "def compress_layer(layer, epsilon=0.10):\n",
    "    \"\"\"\n",
    "    Compresses a layer using SVD if the compression is beneficial.\n",
    "    Args:\n",
    "        layer (nn.Module): The layer to compress.\n",
    "        epsilon (float): The energy threshold for compression.\n",
    "    Returns:\n",
    "        nn.Module: The compressed layer or the original layer if compression is not beneficial.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        # handle Linear layers\n",
    "        W = layer.weight.data.cpu()\n",
    "        U, S, Vh = torch.linalg.svd(W, full_matrices=False)\n",
    "        energy = torch.cumsum(S**2, dim=0) / torch.sum(S**2)\n",
    "        rank = torch.searchsorted(energy, 1 - epsilon).item() + 1\n",
    "        old_size = W.numel()\n",
    "        new_size = rank * (W.shape[0] + W.shape[1])\n",
    "        if new_size < old_size:\n",
    "            print(f\"Compressing Linear layer: old size = {old_size}, new size = {new_size}\")\n",
    "            U_r = U[:, :rank] @ torch.diag(S[:rank])\n",
    "            V_r = Vh[:rank, :]\n",
    "            compressed_layer = nn.Sequential(\n",
    "                nn.Linear(W.shape[1], rank, bias=False),\n",
    "                nn.Linear(rank, W.shape[0], bias=True)\n",
    "            )\n",
    "            compressed_layer[0].weight.data = V_r.to(device)\n",
    "            compressed_layer[1].weight.data = U_r.to(device)\n",
    "            compressed_layer[1].bias.data = layer.bias.data.to(device)\n",
    "            return compressed_layer\n",
    "        \n",
    "    elif isinstance(layer, nn.Conv2d):\n",
    "        # handle Conv2d layers\n",
    "        W = layer.weight.data.cpu()  # shape: [out_channels, in_channels, kH, kW]\n",
    "        OC, IC, kH, kW = W.shape\n",
    "        W_flat = W.view(OC, -1)  # shape: [OC, IC*kH*kW]\n",
    "        U, S, Vh = torch.linalg.svd(W_flat, full_matrices=False)\n",
    "        energy = torch.cumsum(S**2, dim=0) / torch.sum(S**2)\n",
    "        rank = torch.searchsorted(energy, 1 - epsilon).item() + 1\n",
    "        old_size = W.numel()\n",
    "        new_size = rank * (IC * kH * kW + OC)\n",
    "        if new_size < old_size:\n",
    "            print(f\"Compressing Conv2d layer: old size = {old_size}, new size = {new_size}\")\n",
    "            U_r = U[:, :rank] @ torch.diag(S[:rank])\n",
    "            V_r = Vh[:rank, :]\n",
    "            conv1 = nn.Conv2d(\n",
    "                in_channels=IC,\n",
    "                out_channels=rank,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=False\n",
    "            )\n",
    "            conv2 = nn.Conv2d(\n",
    "                in_channels=rank,\n",
    "                out_channels=OC,\n",
    "                kernel_size=(kH, kW),\n",
    "                stride=layer.stride,\n",
    "                padding=layer.padding,\n",
    "                bias=(layer.bias is not None)\n",
    "            )\n",
    "            conv1.weight.data = V_r.view(rank, IC, kH, kW).to(device)\n",
    "            conv2.weight.data = U_r.view(OC, rank, 1, 1).to(device)\n",
    "            if layer.bias is not None:\n",
    "                conv2.bias.data = layer.bias.data.to(device)\n",
    "            return nn.Sequential(conv1, conv2)\n",
    "    return layer  # return the original layer if compression is not beneficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f3a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing Conv2d layer: old size = 1728, new size = 455\n",
      "Compressing Conv2d layer: old size = 4096, new size = 1536\n",
      "Compressing Conv2d layer: old size = 36864, new size = 14080\n",
      "Compressing Conv2d layer: old size = 16384, new size = 6400\n",
      "Compressing Conv2d layer: old size = 16384, new size = 6080\n",
      "Compressing Conv2d layer: old size = 16384, new size = 6400\n",
      "Compressing Conv2d layer: old size = 36864, new size = 14720\n",
      "Compressing Conv2d layer: old size = 16384, new size = 6400\n",
      "Compressing Conv2d layer: old size = 16384, new size = 6400\n",
      "Compressing Conv2d layer: old size = 36864, new size = 14720\n",
      "Compressing Conv2d layer: old size = 16384, new size = 6400\n",
      "Compressing Conv2d layer: old size = 32768, new size = 12288\n",
      "Compressing Conv2d layer: old size = 147456, new size = 58880\n",
      "Compressing Conv2d layer: old size = 65536, new size = 24960\n",
      "Compressing Conv2d layer: old size = 131072, new size = 47616\n",
      "Compressing Conv2d layer: old size = 65536, new size = 25600\n",
      "Compressing Conv2d layer: old size = 147456, new size = 58880\n",
      "Compressing Conv2d layer: old size = 65536, new size = 24960\n",
      "Compressing Conv2d layer: old size = 65536, new size = 25600\n",
      "Compressing Conv2d layer: old size = 147456, new size = 58880\n",
      "Compressing Conv2d layer: old size = 65536, new size = 24960\n",
      "Compressing Conv2d layer: old size = 65536, new size = 24960\n",
      "Compressing Conv2d layer: old size = 147456, new size = 58880\n",
      "Compressing Conv2d layer: old size = 65536, new size = 24960\n",
      "Compressing Conv2d layer: old size = 131072, new size = 49152\n",
      "Compressing Conv2d layer: old size = 589824, new size = 235520\n",
      "Compressing Conv2d layer: old size = 262144, new size = 98560\n",
      "Compressing Conv2d layer: old size = 524288, new size = 192000\n",
      "Compressing Conv2d layer: old size = 262144, new size = 101120\n",
      "Compressing Conv2d layer: old size = 589824, new size = 235520\n",
      "Compressing Conv2d layer: old size = 262144, new size = 99840\n",
      "Compressing Conv2d layer: old size = 262144, new size = 101120\n",
      "Compressing Conv2d layer: old size = 589824, new size = 238080\n",
      "Compressing Conv2d layer: old size = 262144, new size = 99840\n",
      "Compressing Conv2d layer: old size = 262144, new size = 101120\n",
      "Compressing Conv2d layer: old size = 589824, new size = 238080\n",
      "Compressing Conv2d layer: old size = 262144, new size = 101120\n",
      "Compressing Conv2d layer: old size = 262144, new size = 101120\n",
      "Compressing Conv2d layer: old size = 589824, new size = 238080\n",
      "Compressing Conv2d layer: old size = 262144, new size = 99840\n",
      "Compressing Conv2d layer: old size = 262144, new size = 101120\n",
      "Compressing Conv2d layer: old size = 589824, new size = 238080\n",
      "Compressing Conv2d layer: old size = 262144, new size = 99840\n",
      "Compressing Conv2d layer: old size = 524288, new size = 193536\n",
      "Compressing Conv2d layer: old size = 2359296, new size = 952320\n",
      "Compressing Conv2d layer: old size = 1048576, new size = 399360\n",
      "Compressing Conv2d layer: old size = 2097152, new size = 764928\n",
      "Compressing Conv2d layer: old size = 1048576, new size = 401920\n",
      "Compressing Conv2d layer: old size = 2359296, new size = 947200\n",
      "Compressing Conv2d layer: old size = 1048576, new size = 399360\n",
      "Compressing Conv2d layer: old size = 1048576, new size = 401920\n",
      "Compressing Conv2d layer: old size = 2359296, new size = 942080\n",
      "Compressing Conv2d layer: old size = 1048576, new size = 396800\n",
      "Compressing Linear layer: old size = 20480, new size = 8232\n"
     ]
    }
   ],
   "source": [
    "def compress_model(model, epsilon=0.50):\n",
    "    \"\"\"\n",
    "    Compresses the given model by applying SVD-based compression to Linear and Conv2d layers.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model to compress.\n",
    "        epsilon (float): The energy threshold for compression.\n",
    "    \n",
    "    Returns:\n",
    "        nn.Module: The compressed model.\n",
    "    \"\"\"\n",
    "    compressed_model = deepcopy(model)  # Create a copy of the input model\n",
    "    for name, module in compressed_model.named_modules():\n",
    "        if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "            if '.' in name:  # Check if the module has a parent\n",
    "                parent, attr = name.rsplit('.', 1)\n",
    "                parent_module = compressed_model\n",
    "                for part in parent.split('.'):\n",
    "                    parent_module = getattr(parent_module, part)\n",
    "            else:  # Handle top-level modules\n",
    "                parent_module = compressed_model\n",
    "                attr = name\n",
    "            setattr(parent_module, attr, compress_layer(module, epsilon))\n",
    "    \n",
    "    return compressed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e392b7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.2146\n",
      "Epoch 2/5, Loss: 0.8451\n",
      "Epoch 3/5, Loss: 0.6818\n",
      "Epoch 4/5, Loss: 0.5658\n",
      "Epoch 5/5, Loss: 0.4714\n",
      "Training complete. Model saved to compressed_model_final_tuning.pth\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and print metrics for the original model\n",
    "acc_orig = evaluate(original_model)\n",
    "example_input = torch.rand(128, 3, 32, 32).to(device)\n",
    "orig_latency_mu, orig_latency_std = estimate_latency(original_model, example_input)\n",
    "size_orig = get_size(original_model)\n",
    "print(f\"Original -> acc: {100*acc_orig:.2f}%, latency: {orig_latency_mu:.2f} ± {orig_latency_std:.2f} ms, size: {size_orig:.2f}MB\")\n",
    "\n",
    "# Iterate over epsilon values\n",
    "for epsilon in [round(x * 0.1, 2) for x in range(1, 10)]:\n",
    "    print(f\"\\nCompressing model with epsilon = {epsilon}...\")\n",
    "    \n",
    "    # Compress the model\n",
    "    compressed_model = compress_model(original_model, epsilon=epsilon)\n",
    "    \n",
    "    # Evaluate compressed model before fine-tuning\n",
    "    acc_comp = evaluate(compressed_model)\n",
    "    print(f\"Compressed -> acc before tuning: {100*acc_comp:.2f}%\")\n",
    "    \n",
    "    # Fine-tune the compressed model\n",
    "    optimizer = torch.optim.Adam(compressed_model.parameters(), lr=1e-3)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "    \n",
    "    train(\n",
    "        compressed_model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        device,\n",
    "        epochs=5,\n",
    "        scheduler=scheduler,\n",
    "        grad_clip=1.0,\n",
    "        save_path=f\"compressed_model_epsilon_{epsilon}_best_model.pt\",\n",
    "        early_stopping_patience=3,\n",
    "        resume=False,\n",
    "    )\n",
    "    \n",
    "    # Evaluate compressed model after fine-tuning\n",
    "    acc_tuned_comp = evaluate(compressed_model)\n",
    "    comp_latency_mu, comp_latency_std = estimate_latency(compressed_model, example_input)\n",
    "    size_comp = get_size(compressed_model)\n",
    "    \n",
    "    # Print metrics for the fine-tuned compressed model\n",
    "    print(f\"Compressed -> acc after tuning: {100*acc_tuned_comp:.2f}%, latency: {comp_latency_mu:.2f} ± {comp_latency_std:.2f} ms, size: {size_comp:.2f}MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
