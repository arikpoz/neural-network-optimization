{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22bb942b",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e81c85c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import time\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6319037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform),\n",
    "    batch_size=128, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform),\n",
    "    batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6a74380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet50_for_cifar10():\n",
    "    model = models.resnet50(weights=None, num_classes=10)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    return model.to(device)\n",
    "\n",
    "model = get_resnet50_for_cifar10()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2048962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, epochs=10, lr=0.01, save_path=\"model.pth\"):\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Model already trained. Loading from {save_path}\")\n",
    "        model.load_state_dict(torch.load(save_path))\n",
    "        return\n",
    "\n",
    "    # no saved model found. training from given model state\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Training complete. Model saved to {save_path}\")\n",
    "\n",
    "# Evaluate models\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93271cb-cb6b-4f15-9774-85262504b3f0",
   "metadata": {},
   "source": [
    "## Define helper functions to measure latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e4ef641-bdfc-4bde-8198-a18cceca5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.starter = torch.cuda.Event(enable_timing=True)\n",
    "            self.ender = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    def start(self):\n",
    "        if self.use_cuda:\n",
    "            self.starter.record()\n",
    "        else:\n",
    "            self.start_time = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        if self.use_cuda:\n",
    "            self.ender.record()\n",
    "            torch.cuda.synchronize()\n",
    "            return self.starter.elapsed_time(self.ender)  # ms\n",
    "        else:\n",
    "            return (time.time() - self.start_time) * 1000  # ms\n",
    "\n",
    "def estimate_latency(model, example_inputs, repetitions=50):\n",
    "    timer = Timer()\n",
    "    timings = np.zeros((repetitions, 1))\n",
    "\n",
    "    # warm-up\n",
    "    for _ in range(5):\n",
    "        _ = model(example_inputs)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for rep in range(repetitions):\n",
    "            timer.start()\n",
    "            _ = model(example_inputs)\n",
    "            elapsed = timer.stop()\n",
    "            timings[rep] = elapsed\n",
    "\n",
    "    return np.mean(timings), np.std(timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4140ffcb-2d1f-48e9-8bfd-6eaac10f110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Measure size\n",
    "def get_size(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size = os.path.getsize(\"temp.p\") / 1e6\n",
    "    os.remove(\"temp.p\")\n",
    "    return size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaaa880-68cf-479c-aded-fdf83de0e643",
   "metadata": {},
   "source": [
    "## Train and Evaluate full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed4a1309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already trained. Loading from full_model_resnet50.pth\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, epochs=10, save_path=\"full_model_resnet50.pth\")\n",
    "\n",
    "# Save the fine-tuned original model\n",
    "original_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2f139fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compress layers\n",
    "def compress_layer(layer, epsilon=0.10):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        # Handle Linear layers\n",
    "        W = layer.weight.data.cpu()\n",
    "        U, S, Vh = torch.linalg.svd(W, full_matrices=False)\n",
    "        energy = torch.cumsum(S**2, dim=0) / torch.sum(S**2)\n",
    "        rank = torch.searchsorted(energy, 1 - epsilon).item() + 1\n",
    "        old_size = W.numel()\n",
    "        new_size = rank * (W.shape[0] + W.shape[1])\n",
    "        if new_size < old_size:\n",
    "            print(f\"Compressing Linear layer: old size = {old_size}, new size = {new_size}\")\n",
    "            U_r = U[:, :rank] @ torch.diag(S[:rank])\n",
    "            V_r = Vh[:rank, :]\n",
    "            compressed_layer = nn.Sequential(\n",
    "                nn.Linear(W.shape[1], rank, bias=False),\n",
    "                nn.Linear(rank, W.shape[0], bias=True)\n",
    "            )\n",
    "            compressed_layer[0].weight.data = V_r.to(device)\n",
    "            compressed_layer[1].weight.data = U_r.to(device)\n",
    "            compressed_layer[1].bias.data = layer.bias.data.to(device)\n",
    "            return compressed_layer\n",
    "    elif isinstance(layer, nn.Conv2d):\n",
    "        # Handle Conv2d layers\n",
    "        W = layer.weight.data.cpu()  # shape: [out_channels, in_channels, kH, kW]\n",
    "        OC, IC, kH, kW = W.shape\n",
    "        W_flat = W.view(OC, -1)  # shape: [OC, IC*kH*kW]\n",
    "        U, S, Vh = torch.linalg.svd(W_flat, full_matrices=False)\n",
    "        energy = torch.cumsum(S**2, dim=0) / torch.sum(S**2)\n",
    "        rank = torch.searchsorted(energy, 1 - epsilon).item() + 1\n",
    "        old_size = W.numel()\n",
    "        new_size = rank * (IC * kH * kW + OC)\n",
    "        if new_size < old_size:\n",
    "            print(f\"Compressing Conv2d layer: old size = {old_size}, new size = {new_size}\")\n",
    "            U_r = U[:, :rank] @ torch.diag(S[:rank])\n",
    "            V_r = Vh[:rank, :]\n",
    "            conv1 = nn.Conv2d(\n",
    "                in_channels=IC,\n",
    "                out_channels=rank,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=False\n",
    "            )\n",
    "            conv2 = nn.Conv2d(\n",
    "                in_channels=rank,\n",
    "                out_channels=OC,\n",
    "                kernel_size=(kH, kW),\n",
    "                stride=layer.stride,\n",
    "                padding=layer.padding,\n",
    "                bias=(layer.bias is not None)\n",
    "            )\n",
    "            conv1.weight.data = V_r.view(rank, IC, kH, kW).to(device)\n",
    "            conv2.weight.data = U_r.view(OC, rank, 1, 1).to(device)\n",
    "            if layer.bias is not None:\n",
    "                conv2.bias.data = layer.bias.data.to(device)\n",
    "            return nn.Sequential(conv1, conv2)\n",
    "    return layer  # Return the original layer if compression is not beneficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd8f3a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing Conv2d layer: old size = 1728, new size = 455\n",
      "Compressing Conv2d layer: old size = 4096, new size = 1536\n",
      "Compressing Conv2d layer: old size = 36864, new size = 14080\n",
      "Compressing Conv2d layer: old size = 16384, new size = 6400\n",
      "Compressing Conv2d layer: old size = 16384, new size = 6080\n",
      "Compressing Conv2d layer: old size = 16384, new size = 6400\n",
      "Compressing Conv2d layer: old size = 36864, new size = 14720\n",
      "Compressing Conv2d layer: old size = 16384, new size = 6400\n",
      "Compressing Conv2d layer: old size = 16384, new size = 6400\n",
      "Compressing Conv2d layer: old size = 36864, new size = 14720\n",
      "Compressing Conv2d layer: old size = 16384, new size = 6400\n",
      "Compressing Conv2d layer: old size = 32768, new size = 12288\n",
      "Compressing Conv2d layer: old size = 147456, new size = 58880\n",
      "Compressing Conv2d layer: old size = 65536, new size = 24960\n",
      "Compressing Conv2d layer: old size = 131072, new size = 47616\n",
      "Compressing Conv2d layer: old size = 65536, new size = 25600\n",
      "Compressing Conv2d layer: old size = 147456, new size = 58880\n",
      "Compressing Conv2d layer: old size = 65536, new size = 24960\n",
      "Compressing Conv2d layer: old size = 65536, new size = 25600\n",
      "Compressing Conv2d layer: old size = 147456, new size = 58880\n",
      "Compressing Conv2d layer: old size = 65536, new size = 24960\n",
      "Compressing Conv2d layer: old size = 65536, new size = 24960\n",
      "Compressing Conv2d layer: old size = 147456, new size = 58880\n",
      "Compressing Conv2d layer: old size = 65536, new size = 24960\n",
      "Compressing Conv2d layer: old size = 131072, new size = 49152\n",
      "Compressing Conv2d layer: old size = 589824, new size = 235520\n",
      "Compressing Conv2d layer: old size = 262144, new size = 98560\n",
      "Compressing Conv2d layer: old size = 524288, new size = 192000\n",
      "Compressing Conv2d layer: old size = 262144, new size = 101120\n",
      "Compressing Conv2d layer: old size = 589824, new size = 235520\n",
      "Compressing Conv2d layer: old size = 262144, new size = 99840\n",
      "Compressing Conv2d layer: old size = 262144, new size = 101120\n",
      "Compressing Conv2d layer: old size = 589824, new size = 238080\n",
      "Compressing Conv2d layer: old size = 262144, new size = 99840\n",
      "Compressing Conv2d layer: old size = 262144, new size = 101120\n",
      "Compressing Conv2d layer: old size = 589824, new size = 238080\n",
      "Compressing Conv2d layer: old size = 262144, new size = 101120\n",
      "Compressing Conv2d layer: old size = 262144, new size = 101120\n",
      "Compressing Conv2d layer: old size = 589824, new size = 238080\n",
      "Compressing Conv2d layer: old size = 262144, new size = 99840\n",
      "Compressing Conv2d layer: old size = 262144, new size = 101120\n",
      "Compressing Conv2d layer: old size = 589824, new size = 238080\n",
      "Compressing Conv2d layer: old size = 262144, new size = 99840\n",
      "Compressing Conv2d layer: old size = 524288, new size = 193536\n",
      "Compressing Conv2d layer: old size = 2359296, new size = 952320\n",
      "Compressing Conv2d layer: old size = 1048576, new size = 399360\n",
      "Compressing Conv2d layer: old size = 2097152, new size = 764928\n",
      "Compressing Conv2d layer: old size = 1048576, new size = 401920\n",
      "Compressing Conv2d layer: old size = 2359296, new size = 947200\n",
      "Compressing Conv2d layer: old size = 1048576, new size = 399360\n",
      "Compressing Conv2d layer: old size = 1048576, new size = 401920\n",
      "Compressing Conv2d layer: old size = 2359296, new size = 942080\n",
      "Compressing Conv2d layer: old size = 1048576, new size = 396800\n",
      "Compressing Linear layer: old size = 20480, new size = 8232\n"
     ]
    }
   ],
   "source": [
    "# Compress the model\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "        if '.' in name:  # Check if the module has a parent\n",
    "            parent, attr = name.rsplit('.', 1)\n",
    "            parent_module = model\n",
    "            for part in parent.split('.'):\n",
    "                parent_module = getattr(parent_module, part)\n",
    "        else:  # Handle top-level modules\n",
    "            parent_module = model\n",
    "            attr = name\n",
    "        setattr(parent_module, attr, compress_layer(module, epsilon=0.50))\n",
    "\n",
    "# Save the compressed model before fine-tuning\n",
    "compressed_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e392b7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.2146\n",
      "Epoch 2/5, Loss: 0.8451\n",
      "Epoch 3/5, Loss: 0.6818\n",
      "Epoch 4/5, Loss: 0.5658\n",
      "Epoch 5/5, Loss: 0.4714\n",
      "Training complete. Model saved to compressed_model_final_tuning.pth\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, epochs=5, save_path=f\"compressed_model_final_tuning.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c4743ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original -> acc: 72.73%, latency: 73.57 ± 0.06 ms, size: 94.38MB\n",
      "Compressed -> acc: 0.10%, latency: 73.42 ± 0.04 ms, size: 37.06MB\n",
      "Tuned Compressed -> acc: 72.70%, 73.49 ± 0.05 ms, size: 37.06MB\n"
     ]
    }
   ],
   "source": [
    "# Compare models\n",
    "acc_orig = evaluate(original_model)\n",
    "acc_comp = evaluate(compressed_model)\n",
    "acc_tuned_comp = evaluate(model)\n",
    "\n",
    "example_input = torch.rand(128, 3, 32, 32).to(device)\n",
    "orig_latency_mu, orig_latency_std = estimate_latency(original_model, example_input)\n",
    "comp_latency_mu, comp_latency_std = estimate_latency(compressed_model, example_input)\n",
    "tuned_latency_mu, tuned_latency_std = estimate_latency(model, example_input)\n",
    "\n",
    "size_orig = get_size(original_model)\n",
    "size_comp = get_size(compressed_model)\n",
    "size_tuned_comp = get_size(model)\n",
    "\n",
    "print(f\"Original -> acc: {100*acc_orig:.2f}%, latency: {orig_latency_mu:.2f} ± {orig_latency_std:.2f} ms, size: {size_orig:.2f}MB\")\n",
    "print(f\"Compressed -> acc: {100%acc_comp:.2f}%, latency: {comp_latency_mu:.2f} ± {comp_latency_std:.2f} ms, size: {size_comp:.2f}MB\")\n",
    "print(f\"Tuned Compressed -> acc: {100*acc_tuned_comp:.2f}%, {tuned_latency_mu:.2f} ± {tuned_latency_std:.2f} ms, size: {size_tuned_comp:.2f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf3ab7a-aaef-4517-84cb-f3c2fc7faab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
